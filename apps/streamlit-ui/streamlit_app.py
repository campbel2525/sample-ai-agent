import os
import json
import time
from typing import Any, Dict, List, Optional

import requests
import streamlit as st

# =============================
# å®šæ•°ï¼ˆä¸Šéƒ¨ã«é›†ç´„ï¼‰
# =============================
# FastAPIã®å›ºå®šURLï¼ˆç’°å¢ƒå¤‰æ•°ã¯ç„¡è¦–ã—ã¦å›ºå®šï¼‰
DEFAULT_FASTAPI_BASE_URL = "http://ai-agent:8000"

# RAGasã®æ—¢å®šã¯OFF
DEFAULT_RUN_RAGAS = False

# ãƒ¢ãƒ‡ãƒ«åã®æ—¢å®šå€¤ï¼ˆæœªå…¥åŠ›æ™‚ã¯APIå´ã®æ—¢å®šã§ã‚‚å‹•ããŒã€UIã§ã¯æ˜ç¤ºï¼‰
DEFAULT_PLANNER_MODEL = "gpt-4o-2024-08-06"
DEFAULT_SUBTASK_TOOL_SELECTION_MODEL = "gpt-4o-2024-08-06"
DEFAULT_SUBTASK_ANSWER_MODEL = "gpt-4o-2024-08-06"
DEFAULT_SUBTASK_REFLECTION_MODEL = "gpt-4o-2024-08-06"
DEFAULT_FINAL_ANSWER_MODEL = "gpt-4o-2024-08-06"

# UIã®é«˜ã•ãƒ»ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
PROMPT_TEXTAREA_HEIGHT = 120
PARAMS_TEXTAREA_HEIGHT = 80
REQUEST_TIMEOUT_SEC = 600

# APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
EXEC_ENDPOINT = "/ai_agents/chatbot/exec"


def init_state():
    if "messages" not in st.session_state:
        st.session_state.messages: List[Dict[str, str]] = []  # {role, content}
    if "last_request" not in st.session_state:
        st.session_state.last_request: Optional[Dict[str, Any]] = None
    if "last_response" not in st.session_state:
        st.session_state.last_response: Optional[Dict[str, Any]] = None
    if "turns" not in st.session_state:
        # å„ã‚¿ãƒ¼ãƒ³ã®è©³ç´°ï¼ˆuserç™ºè©±ãƒ»assistantå¿œç­”ãƒ»è©³ç´°çµæœï¼‰ã‚’ä¿æŒ
        st.session_state.turns: List[Dict[str, Any]] = []


def to_chat_history(messages: List[Dict[str, str]]) -> List[Dict[str, str]]:
    # FastAPIã®ChatCompletionMessageParamã«åˆã‚ã›ãŸæœ€ä½é™ã®å½¢å¼
    out = []
    for m in messages:
        if m.get("role") in ("user", "assistant") and m.get("content"):
            out.append({"role": m["role"], "content": m["content"]})
    return out


def parse_json_or_none(label: str, raw: str) -> Optional[Dict[str, Any]]:
    if not raw:
        return None
    try:
        data = json.loads(raw)
        if data is None:
            return None
        if not isinstance(data, dict):
            st.warning(f"{label} ã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ(JSON)ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚ç„¡è¦–ã—ã¾ã™ã€‚")
            return None
        return data
    except Exception as e:
        st.error(f"{label} ã®JSONãŒä¸æ­£ã§ã™: {e}")
        return None


def main():
    st.set_page_config(page_title="AI Agent Chat UI", page_icon="ğŸ¤–", layout="wide")
    init_state()

    # å›ºå®šURLï¼ˆå…¥åŠ›æ¬„ã¯å»ƒæ­¢ï¼‰
    with st.sidebar:
        # å‚è€ƒãƒªãƒ³ã‚¯ï¼ˆFastAPIã®APIä»•æ§˜ï¼‰
        st.caption("è©³ã—ãã¯ http://localhost:8000/docs å‚ç…§")

        st.subheader("RAGas")
        is_run_ragas = st.checkbox("RAGasã‚’å®Ÿè¡Œã™ã‚‹", value=DEFAULT_RUN_RAGAS)
        ragas_reference = st.text_area("RAGas reference", value="")

        st.subheader("ãƒ¢ãƒ‡ãƒ«è¨­å®š (æœªå…¥åŠ›ã¯APIæ—¢å®š)")
        planner_model_name = st.text_input(
            "planner_model_name", value=DEFAULT_PLANNER_MODEL
        )
        subtask_tool_selection_model_name = st.text_input(
            "subtask_tool_selection_model_name",
            value=DEFAULT_SUBTASK_TOOL_SELECTION_MODEL,
        )
        subtask_answer_model_name = st.text_input(
            "subtask_answer_model_name", value=DEFAULT_SUBTASK_ANSWER_MODEL
        )
        subtask_reflection_model_name = st.text_input(
            "subtask_reflection_model_name", value=DEFAULT_SUBTASK_REFLECTION_MODEL
        )
        final_answer_model_name = st.text_input(
            "final_answer_model_name", value=DEFAULT_FINAL_ANSWER_MODEL
        )

        st.subheader("ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿(JSON) (æœªå…¥åŠ›ã¯None)")
        planner_params_raw = st.text_area(
            "planner_params", height=PARAMS_TEXTAREA_HEIGHT
        )
        subtask_tool_selection_params_raw = st.text_area(
            "subtask_tool_selection_params", height=PARAMS_TEXTAREA_HEIGHT
        )
        subtask_answer_params_raw = st.text_area(
            "subtask_answer_params", height=PARAMS_TEXTAREA_HEIGHT
        )
        subtask_reflection_params_raw = st.text_area(
            "subtask_reflection_params", height=PARAMS_TEXTAREA_HEIGHT
        )
        final_answer_params_raw = st.text_area(
            "final_answer_params", height=PARAMS_TEXTAREA_HEIGHT
        )

        st.subheader("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¸Šæ›¸ã (æœªå…¥åŠ›ã¯æ—¢å®š)")
        with st.expander("Planner prompts"):
            ai_agent_planner_system_prompt = st.text_area(
                "ai_agent_planner_system_prompt", height=PROMPT_TEXTAREA_HEIGHT
            )
            ai_agent_planner_user_prompt = st.text_area(
                "ai_agent_planner_user_prompt", height=PROMPT_TEXTAREA_HEIGHT
            )
        with st.expander("Subtask prompts"):
            ai_agent_subtask_system_prompt = st.text_area(
                "ai_agent_subtask_system_prompt", height=PROMPT_TEXTAREA_HEIGHT
            )
            ai_agent_subtask_tool_selection_user_prompt = st.text_area(
                "ai_agent_subtask_tool_selection_user_prompt",
                height=PROMPT_TEXTAREA_HEIGHT,
            )
            ai_agent_subtask_reflection_user_prompt = st.text_area(
                "ai_agent_subtask_reflection_user_prompt", height=PROMPT_TEXTAREA_HEIGHT
            )
            ai_agent_subtask_retry_answer_user_prompt = st.text_area(
                "ai_agent_subtask_retry_answer_user_prompt",
                height=PROMPT_TEXTAREA_HEIGHT,
            )
        with st.expander("Final answer prompts"):
            ai_agent_create_last_answer_system_prompt = st.text_area(
                "ai_agent_create_last_answer_system_prompt",
                height=PROMPT_TEXTAREA_HEIGHT,
            )
            ai_agent_create_last_answer_user_prompt = st.text_area(
                "ai_agent_create_last_answer_user_prompt", height=PROMPT_TEXTAREA_HEIGHT
            )

    st.title("ğŸ¤– Chatbot AI Agent")

    # æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤ºï¼ˆè©³ç´°ã”ã¨ä¿æŒã—ã¦ã„ã‚‹å ´åˆã¯ãã¡ã‚‰ã‚’å„ªå…ˆï¼‰
    if st.session_state.turns:
        for t in st.session_state.turns:
            user_text = t.get("user", "")
            asst_text = t.get("assistant", "")
            detail = t.get("detail", {})

            if user_text:
                with st.chat_message("user"):
                    st.markdown(user_text)
            if asst_text:
                with st.chat_message("assistant"):
                    st.markdown(asst_text)
                    if detail:
                        with st.expander("è©³ç´°çµæœ (plan, subtasks, RAGas, Langfuse)"):
                            if "latency_sec" in detail:
                                st.write({"latency_sec": detail["latency_sec"]})
                            if "plan" in detail and detail["plan"] is not None:
                                st.subheader("Plan")
                                st.write(detail["plan"])
                            if "subtasks" in detail and detail["subtasks"] is not None:
                                st.subheader("Subtasks")
                                st.write(detail["subtasks"])
                            if "ragas_scores" in detail:
                                st.subheader("RAGas scores")
                                st.write(detail.get("ragas_scores", {}))
                            if "langfuse_session_id" in detail and detail["langfuse_session_id"]:
                                st.subheader("Langfuse session id")
                                st.code(str(detail["langfuse_session_id"]))
    else:
        for m in st.session_state.messages:
            with st.chat_message(m["role"]):
                st.markdown(m["content"])

    user_input = st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›...")
    if user_input:
        # é€ä¿¡: ç›´å‰ã¾ã§ã®å±¥æ­´ã‚’chat_historyã«
        st.session_state.messages.append({"role": "user", "content": user_input})
        # ç›´è¿‘ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¯å³æ™‚è¡¨ç¤ºï¼ˆæ¬¡å›ãƒªãƒ­ãƒ¼ãƒ‰å¾…ã¡ã«ã—ãªã„ï¼‰
        with st.chat_message("user"):
            st.markdown(user_input)

        chat_history = to_chat_history(st.session_state.messages[:-1])

        # JSONãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è§£æ
        planner_params = parse_json_or_none("planner_params", planner_params_raw)
        subtask_tool_selection_params = parse_json_or_none(
            "subtask_tool_selection_params", subtask_tool_selection_params_raw
        )
        subtask_answer_params = parse_json_or_none(
            "subtask_answer_params", subtask_answer_params_raw
        )
        subtask_reflection_params = parse_json_or_none(
            "subtask_reflection_params", subtask_reflection_params_raw
        )
        final_answer_params = parse_json_or_none(
            "final_answer_params", final_answer_params_raw
        )

        # ç©ºæ–‡å­—ã¯Noneã¸
        def nvl(s: str) -> Optional[str]:
            return s if s else None

        # RAGasã®å¿…é ˆãƒã‚§ãƒƒã‚¯ï¼ˆæœªå…¥åŠ›ãªã‚‰ä»Šå›ã ã‘è‡ªå‹•ç„¡åŠ¹åŒ–ï¼‰
        ragas_ref_trim = (ragas_reference or "").strip()
        ragas_enabled = bool(is_run_ragas and ragas_ref_trim)
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯å‡ºã•ãšé™ã‹ã«ç„¡åŠ¹åŒ–

        payload: Dict[str, Any] = {
            "question": user_input,
            "chat_history": chat_history,
            "planner_model_name": nvl(planner_model_name),
            "subtask_tool_selection_model_name": nvl(subtask_tool_selection_model_name),
            "subtask_answer_model_name": nvl(subtask_answer_model_name),
            "subtask_reflection_model_name": nvl(subtask_reflection_model_name),
            "final_answer_model_name": nvl(final_answer_model_name),
            "planner_params": planner_params,
            "subtask_tool_selection_params": subtask_tool_selection_params,
            "subtask_answer_params": subtask_answer_params,
            "subtask_reflection_params": subtask_reflection_params,
            "final_answer_params": final_answer_params,
            "ai_agent_planner_system_prompt": nvl(ai_agent_planner_system_prompt),
            "ai_agent_planner_user_prompt": nvl(ai_agent_planner_user_prompt),
            "ai_agent_subtask_system_prompt": nvl(ai_agent_subtask_system_prompt),
            "ai_agent_subtask_tool_selection_user_prompt": nvl(
                ai_agent_subtask_tool_selection_user_prompt
            ),
            "ai_agent_subtask_reflection_user_prompt": nvl(
                ai_agent_subtask_reflection_user_prompt
            ),
            "ai_agent_subtask_retry_answer_user_prompt": nvl(
                ai_agent_subtask_retry_answer_user_prompt
            ),
            "ai_agent_create_last_answer_system_prompt": nvl(
                ai_agent_create_last_answer_system_prompt
            ),
            "ai_agent_create_last_answer_user_prompt": nvl(
                ai_agent_create_last_answer_user_prompt
            ),
            "is_run_ragas": ragas_enabled,
            "ragas_reference": ragas_ref_trim if ragas_enabled else None,
        }

        st.session_state.last_request = payload

        with st.chat_message("assistant"):
            with st.spinner("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œä¸­..."):
                try:
                    t0 = time.time()
                    resp = requests.post(
                        f"{DEFAULT_FASTAPI_BASE_URL}{EXEC_ENDPOINT}",
                        json=payload,
                        timeout=REQUEST_TIMEOUT_SEC,
                    )
                    latency = time.time() - t0
                    if resp.status_code != 200:
                        st.error(f"APIã‚¨ãƒ©ãƒ¼: {resp.status_code} {resp.text}")
                        st.session_state.messages.append(
                            {
                                "role": "assistant",
                                "content": "ã™ã¿ã¾ã›ã‚“ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
                            }
                        )
                    else:
                        data = resp.json()
                        st.session_state.last_response = data
                        answer = data.get("answer") or ""
                        st.markdown(answer)
                        st.session_state.messages.append(
                            {"role": "assistant", "content": answer}
                        )

                        with st.expander("è©³ç´°çµæœ (plan, subtasks, RAGas, Langfuse)"):
                            latency_sec = round(latency, 2)
                            st.write({"latency_sec": latency_sec})
                            plan = (data.get("ai_agent_result") or {}).get("plan")
                            if plan:
                                st.subheader("Plan")
                                st.write(plan)
                            subtasks = (data.get("ai_agent_result") or {}).get(
                                "subtasks_detail"
                            )
                            if subtasks:
                                st.subheader("Subtasks")
                                st.write(subtasks)
                            ragas_scores = (data.get("ragas_result") or {}).get(
                                "scores"
                            )
                            st.subheader("RAGas scores")
                            st.write(ragas_scores)
                            sid = data.get("langfuse_session_id")
                            st.subheader("Langfuse session id")
                            st.code(sid)

                        # ã‚¿ãƒ¼ãƒ³è©³ç´°ã‚’å±¥æ­´ã«ä¿å­˜ï¼ˆæ¬¡å›ä»¥é™ã®å†æç”»ã§ã‚‚ä¿æŒï¼‰
                        st.session_state.turns.append(
                            {
                                "user": user_input,
                                "assistant": answer,
                                "detail": {
                                    "latency_sec": round(latency, 2),
                                    "plan": plan,
                                    "subtasks": subtasks,
                                    "ragas_scores": ragas_scores or {},
                                    "langfuse_session_id": sid,
                                },
                            }
                        )
                except Exception as e:
                    st.error(f"é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
                    st.session_state.messages.append(
                        {
                            "role": "assistant",
                            "content": "ã™ã¿ã¾ã›ã‚“ã€é€šä¿¡ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
                        }
                    )

    st.divider()
    cols = st.columns(3)
    if cols[0].button("å±¥æ­´ã‚¯ãƒªã‚¢"):
        st.session_state.messages = []
        st.session_state.last_request = None
        st.session_state.last_response = None
        st.session_state.turns = []
        st.experimental_rerun()
    if cols[1].button("æœ€å¾Œã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆè¡¨ç¤º"):
        st.json(st.session_state.last_request)
    if cols[2].button("æœ€å¾Œã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹è¡¨ç¤º"):
        st.json(st.session_state.last_response)


if __name__ == "__main__":
    main()
