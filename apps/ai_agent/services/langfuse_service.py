"""Langfuseãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°æ©Ÿèƒ½"""

from typing import Optional

from langfuse import Langfuse
from langfuse.openai import openai as langfuse_openai
from openai.types.chat import ChatCompletionMessageParam

from ai_agents.agents.general_purpose_ai_agent.agent import Agent
from ai_agents.agents.general_purpose_ai_agent.models import AgentResult
from config.custom_logger import setup_logger

LANGFUSE_AVAILABLE = True

logger = setup_logger(__file__)


class LangfuseTracer:
    """Langfuseãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(
        self,
        public_key: str,
        secret_key: str,
        host: str,
    ) -> None:
        self.public_key = public_key
        self.secret_key = secret_key
        self.host = host
        self.langfuse = None

        try:
            self.langfuse = Langfuse(
                public_key=self.public_key,
                secret_key=self.secret_key,
                host=self.host,
            )
            logger.info("âœ… Langfuse client initialized successfully")
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to initialize Langfuse client: {e}")
            self.langfuse = None

    def is_available(self) -> bool:
        """LangfuseãŒåˆ©ç”¨å¯èƒ½ã‹ã©ã†ã‹ã‚’è¿”ã™"""
        return self.langfuse is not None

    def flush(self) -> None:
        """Langfuseã«ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡ã™ã‚‹"""
        if self.langfuse is None:  # â† ç›´æ¥ None ãƒã‚§ãƒƒã‚¯
            return
        try:
            self.langfuse.flush()  # ã“ã“ã§ mypy OK
        except Exception as e:
            logger.warning(f"Failed to flush Langfuse data: {e}")

    def get_openai_client(self, api_key: str, base_url: str):
        """Langfuseçµ±åˆOpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—ã™ã‚‹"""
        if self.is_available() and langfuse_openai:
            try:
                return langfuse_openai.OpenAI(
                    api_key=api_key,
                    base_url=base_url,
                )
            except Exception as e:
                logger.warning(
                    f"Failed to create Langfuse-integrated OpenAI client: {e}"
                )

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ¨™æº–ã®OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        from openai import OpenAI

        return OpenAI(api_key=api_key, base_url=base_url)

    def get_client(self):
        """å†…éƒ¨ã§åˆæœŸåŒ–ã—ãŸ Langfuse ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’è¿”ã™"""
        return self.langfuse


def run_agent_with_langfuse(
    agent: Agent,
    query: str,
    chat_history: list[ChatCompletionMessageParam],
    langfuse_public_key: str,
    langfuse_secret_key: str,
    langfuse_host: str,
    langfuse_session_id: Optional[str] = None,
    langfuse_user_id: Optional[int] = None,
    langfuse_trace_name: str = "ai_agent_execution",
) -> AgentResult:
    """
    ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’Langfuseãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ä»˜ãã§å®Ÿè¡Œã™ã‚‹
    Args:
        agent (Agent): ç´”ç²‹ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        query (str): å…¥åŠ›ã®è³ªå•
        langfuse_public_key (str): Langfuseã®Public Key
        langfuse_secret_key (str): Langfuseã®Secret Key
        langfuse_host (str): Langfuseã®Host URL
        session_id (Optional[str]): Langfuseã®ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆä¼šè©±ã‚„ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’æŸã­ãŸã„ã¨ãã«æŒ‡å®šï¼‰
        user_id (Optional[str]): Langfuseã®ãƒ¦ãƒ¼ã‚¶ãƒ¼IDï¼ˆä»»æ„ãƒ»é›†è¨ˆã‚„æ¤œç´¢ç”¨ï¼‰
        trace_name (str): ãƒˆãƒ¬ãƒ¼ã‚¹åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: "ai_agent_execution"ï¼‰

    Returns:
        AgentResult: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè¡Œçµæœ
    """
    tracer = LangfuseTracer(
        public_key=langfuse_public_key,
        secret_key=langfuse_secret_key,
        host=langfuse_host,
    )
    if not tracer.is_available():
        raise Exception(
            "Langfuse tracer is not available with the provided credentials."
        )

    langfuse_client = tracer.get_openai_client(
        api_key=agent.openai_api_key,
        base_url=agent.openai_base_url,
    )
    original_client = agent.client
    try:
        agent.client = langfuse_client
        logger.info("âœ… Temporarily using Langfuse-integrated OpenAI client")

        lf = tracer.get_client()
        with lf.start_as_current_span(name=langfuse_trace_name) as span:
            # AgentSetting ã®æ¦‚è¦ï¼ˆå­˜åœ¨ã™ã‚Œã°ï¼‰ã‚’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ä»˜ä¸
            settings_meta = None
            s = getattr(agent, "settings", None)
            if s is not None:
                settings_meta = {
                    "planner_model": s.planner.model_name,
                    "subtask_select_tool_model": s.subtask_select_tool.model_name,
                    "subtask_reflection_model": s.subtask_reflection.model_name,
                    "subtask_retry_answer_model": s.subtask_retry_answer.model_name,
                    "final_answer_model": s.final_answer.model_name,
                }

            span.update_trace(
                name=langfuse_trace_name,  # â˜… å¼•æ•°ã‚’ä½¿ç”¨
                input={"query": query, "chat_history": chat_history},
                metadata={
                    "agent_type": "general_purpose_ai_agent",
                    "max_challenge_count": agent.max_challenge_count,
                    "tools": [tool.name for tool in agent.tools],
                    "has_chat_history": bool(chat_history),
                    "chat_history_length": len(chat_history) if chat_history else 0,
                    "agent_settings": settings_meta,
                },
                session_id=langfuse_session_id,
                user_id=langfuse_user_id,
            )

            logger.info(
                f"ğŸš€ Starting agent execution with Langfuse tracing ({langfuse_trace_name})..."  # noqa: E501
            )
            agent_result = agent.run_agent(query, chat_history)

            plan = getattr(agent_result, "plan", None)
            output = {
                "answer": agent_result.answer,
                "plan": plan.subtasks if plan is not None else None,
                "subtask_count": len(getattr(agent_result, "subtasks", [])),
            }
            metadata = {
                "execution_status": "success",
                "total_subtasks": len(getattr(agent_result, "subtasks", [])),
            }
            span.update_trace(
                output=output,
                metadata=metadata,
            )

            logger.info("âœ… Agent execution completed successfully")
            return agent_result
    finally:
        agent.client = original_client
        tracer.flush()
